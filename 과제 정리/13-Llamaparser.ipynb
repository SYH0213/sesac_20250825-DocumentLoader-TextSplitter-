{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8382978f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LlamaParser\n",
    " \n",
    "LlamaParse는 LlamaIndex에서 개발한 문서 파싱 서비스로, 대규모 언어 모델(LLM)을 위해 특별히 설계되었습니다. 주요 특징은 다음과 같습니다:\n",
    "\n",
    "- PDF, Word, PowerPoint, Excel 등 다양한 문서 형식 지원\n",
    "- 자연어 지시를 통한 맞춤형 출력 형식 제공\n",
    "- 복잡한 표와 이미지 추출 기능\n",
    "- JSON 모드 지원\n",
    "- 외국어 지원\n",
    "\n",
    "LlamaParse는 독립형 API로 제공되며, LlamaCloud 플랫폼의 일부로도 사용 가능합니다. 이 서비스는 문서를 파싱하고 정제하여 검색 증강 생성(RAG) 등 LLM 기반 애플리케이션의 성능을 향상시키는 것을 목표로 합니다.\n",
    "\n",
    "사용자는 무료로 하루 1,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보할 수 있습니다. LlamaParse는 현재 공개 베타 버전으로 제공되고 있으며, 지속적으로 기능이 확장되고 있습니다.\n",
    "\n",
    "- 링크: https://cloud.llamaindex.ai\n",
    "\n",
    "**API 키 설정**\n",
    "- API 키를 발급 후 `.env` 파일에 `LLAMA_CLOUD_API_KEY` 에 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de92eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install llama-index-core llama-parse llama-index-readers-file python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850910e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b850dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getenv(\"LLAMA_CLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff3b85",
   "metadata": {},
   "source": [
    "기본 파서 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a94cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id e7a4d3de-b0af-4308-a83b-db07d52964aa\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# 파서 설정\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\"과 \"text\" 사용 가능\n",
    "    num_workers=8,  # worker 수 (기본값: 4)\n",
    "    verbose=True,\n",
    "    language=\"ko\",\n",
    ")\n",
    "\n",
    "# SimpleDirectoryReader를 사용하여 파일 파싱\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "# LlamaParse로 파일 파싱\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4aabfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 페이지 수 확인\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a08fb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='5d2d80ee-f764-441f-a7c5-da39e28411f6', embedding=None, metadata={'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf', 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_type': 'application/pdf', 'file_size': 975735, 'creation_date': '2025-08-21', 'last_modified_date': '2025-08-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='# 2023년 12월호\\n\\n# 인공지능 산업의 최신 동향\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d4e1b",
   "metadata": {},
   "source": [
    "LlamaIndex -> LangChain Document 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10be578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db68c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "# 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\n",
      "\n",
      "# KEY Contents\n",
      "\n",
      "- 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을 위한 협력 방안을 담은 블레츨리 선언을 발표\n",
      "- 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며, 영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정\n",
      "\n",
      "# AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\n",
      "\n",
      "- 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에 참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표\n",
      "- 선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이 중요하다고 강조했으며, 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여 AI 시스템의 안전을 보장할 책임이 있다고 지적\n",
      "- 각국은 AI 안전 보장을 위해 첨단 AI 개발기업의 투명성 향상, 적절한 평가지표와 안전 테스트 도구 개발, 공공부문 역량 구축과 과학 연구개발 등의 분야에서 협력하기로 합의\n",
      "\n",
      "# 영국 총리, 정부 주도의 첨단 AI 시스템 안전 테스트 계획 발표\n",
      "\n",
      "- 리시 수낙 영국 총리는 AI 안전성 정상회의를 마무리하며 첨단 AI 모델에 대한 안전성 시험 계획 수립과 테스트 수행을 주도할 영국 AI 안전 연구소의 출범을 발표\n",
      "- 첨단 AI 모델의 안전 테스트는 국가 안보와 안전, 사회적 피해를 포함한 여러 잠재적 유해 기능에 대한 시험을 포함하며, 참석자들은 정부 주도의 외부 안전 테스트에 합의\n",
      "- 각국 정부는 테스트와 기타 안전 연구를 위한 공공부문 역량에 투자하고, 테스트 결과가 다른 국가와 관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의\n",
      "\n",
      "- 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of the Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한 기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획\n",
      "- 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며, 프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\n",
      "\n",
      "☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01. Gov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit concludes, 2023.11.02.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ec141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 975735,\n",
       " 'creation_date': '2025-08-21',\n",
       " 'last_modified_date': '2025-08-21'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 출력\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845a3bc",
   "metadata": {},
   "source": [
    "## MultiModal Model 로 파싱\n",
    "\n",
    "**주요 파라미터**\n",
    "\n",
    "- `use_vendor_multimodal_model`: 멀티모달 모델 사용 여부를 지정합니다. `True`로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.\n",
    "\n",
    "- `vendor_multimodal_model_name`: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 \"openai-gpt4o\"를 사용하고 있습니다.\n",
    "\n",
    "- `vendor_multimodal_api_key`: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.\n",
    "\n",
    "- `result_type`: 파싱 결과의 형식을 지정합니다. \"markdown\"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.\n",
    "\n",
    "- `language`: 파싱할 문서의 언어를 지정합니다. \"ko\"로 설정되어 한국어로 처리됩니다.\n",
    "\n",
    "- `skip_diagonal_text`: 대각선 텍스트를 건너뛸지 여부를 결정합니다.\n",
    "\n",
    "- `page_separator`: 페이지 구분자를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"data/2103.15348v2.pdf\"\n",
    "parsed_docs = documents.load_data(file_path=file_path)\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "# os.path.splitext()를 사용하여 경로와 확장자를 분리하고, 새로운 확장자를 붙입니다.\n",
    "# file_root는 'data/2103.15348v2'가 됩니다.\n",
    "file_root, _ = os.path.splitext(file_path)\n",
    "output_file_path = file_root + \".md\"\n",
    "\n",
    "# 1. 모든 페이지의 page_content를 리스트로 추출합니다.\n",
    "#    각 페이지 사이를 두 줄 띄어쓰기(\\n\\n)로 구분하여 가독성을 높입니다.\n",
    "full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 2. 추출한 전체 텍스트를 파일에 저장합니다.\n",
    "#    'w' 모드는 파일을 쓰기 모드로 열며, encoding='utf-8'은 한글 깨짐을 방지합니다.\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(f\"✅ 파일 저장 완료: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    # skip_diagonal_text=True,\n",
    "    # page_separator=\"\\n=================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c986f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing 된 결과\n",
    "parsed_docs = documents.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe71f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[18].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc038703",
   "metadata": {},
   "source": [
    "아래와 같이 사용자 정의 인스트럭션을 지정하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing instruction 을 지정합니다.\n",
    "parsing_instruction = (\n",
    "    \"You are parsing a brief of AI Report. Please extract tables in markdown format.\"\n",
    ")\n",
    "\n",
    "# LlamaParse 설정\n",
    "parser = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    parsing_instruction=parsing_instruction,\n",
    ")\n",
    "\n",
    "# parsing 된 결과\n",
    "parsed_docs = parser.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d87bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown 형식으로 추출된 테이블 확인\n",
    "print(docs[-2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd730b",
   "metadata": {},
   "source": [
    "### Llama를 함수로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ceb86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 './data/sample_withdog.pdf' 파일 파싱을 시작합니다...\n",
      "Started parsing the file under job_id e1b064a9-e691-42f8-8eb2-53b3ac78bcdf\n",
      "✅ 파일 저장 완료: ./data/sample_withdog.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\")\n",
    "\n",
    "\n",
    "def pdf_parser(pdf_file_path: str):\n",
    "    \"\"\"\n",
    "    PDF 파일을 파싱하여 그 내용을 Markdown 파일로 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): 처리할 PDF 파일의 경로.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 '{pdf_file_path}' 파일 파싱을 시작합니다...\")\n",
    "\n",
    "    try:\n",
    "        # parsing instruction 을 지정합니다.\n",
    "        parsing_instruction = (\n",
    "            \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    "        )\n",
    "\n",
    "        # LlamaParse 설정\n",
    "        parser = LlamaParse(\n",
    "            use_vendor_multimodal_model=True,\n",
    "            vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "            vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            result_type=\"markdown\",\n",
    "            # parsing_mode=\"Unstructured\",\n",
    "            language=\"ko\",\n",
    "            parsing_instruction=parsing_instruction,\n",
    "        )\n",
    "\n",
    "        # 1. LlamaParse를 사용하여 PDF 파일을 로드합니다.\n",
    "        # 'documents' 객체는 이 함수 외부에서 미리 정의되어 있어야 합니다.\n",
    "        parsed_docs = documents.load_data(file_path=pdf_file_path)\n",
    "\n",
    "        # 2. LangChain 형식의 도큐먼트로 변환합니다.\n",
    "        docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "        # 3. 저장할 Markdown 파일의 경로를 생성합니다. (확장자 변경)\n",
    "        file_root, _ = os.path.splitext(pdf_file_path)\n",
    "        output_file_path = file_root + \".md\"\n",
    "\n",
    "        # 4. 모든 페이지의 내용을 하나의 텍스트로 합칩니다.\n",
    "        #    페이지 사이는 두 줄로 띄어 가독성을 높입니다.\n",
    "        full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # 5. 추출된 전체 텍스트를 .md 파일로 저장합니다.\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "\n",
    "        print(f\"✅ 파일 저장 완료: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 오류: 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "# --- 함수 사용 예시 ---\n",
    "# 이 코드를 실행하기 전에 'documents' 파서 객체를 초기화해야 합니다.\n",
    "# file_to_parse = \"data/디지털정부혁신추진계획.pdf\"\n",
    "file_to_parse = \"./data/클라우드네이티브1-2.pdf\"\n",
    "pdf_parser(file_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from llama_cloud_services import LlamaParse\n",
    "\n",
    "# --- 1. Llama Cloud API 키 설정 ---\n",
    "# https://cloud.llamaindex.ai/ 에서 발급받은 API 키를 환경 변수에 설정해야 합니다.\n",
    "if \"LLAMA_CLOUD_API_KEY\" not in os.environ:\n",
    "    # 아래 주석을 해제하고 실제 키를 입력하거나, 시스템 환경 변수를 설정하세요.\n",
    "    # os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-...\" \n",
    "    print(\"경고: 'LLAMA_CLOUD_API_KEY' 환경 변수가 설정되지 않았습니다.\")\n",
    "\n",
    "# --- 2. 파싱할 PDF 파일 경로 ---\n",
    "pdf_file_path = \"./data/클라우드네이티브1-3.pdf\" # 실제 파일 경로로 수정하세요.\n",
    "\n",
    "# --- 3. LlamaParse 객체에 고급 옵션 설정 ---\n",
    "# 요청하신 모든 옵션을 포함하여 파서를 설정합니다.\n",
    "# result_mode=\"markdown\"이 최종 출력을 마크다운으로 지정하는 핵심 부분입니다.\n",
    "parser = LlamaParse(\n",
    "    result_mode=\"markdown\",                # 최종 결과 형식을 마크다운으로 지정\n",
    "    parse_mode=\"parse_page_with_agent\",    # 에이전트 기반의 페이지별 파싱 모드 사용\n",
    "    model=\"openai-gpt-4o-mini\",            # 파싱에 사용할 LLM 모델 (gpt-4-1-mini -> gpt-4o-mini로 변경 권장)\n",
    "    language=\"ko\",\n",
    "    high_res_ocr=True                      # 고해상도 OCR 활성화 (스캔 문서 처리에 유용)\n",
    ")\n",
    "\n",
    "# --- 4. 비동기 함수로 파일 파싱 실행 ---\n",
    "async def parse_document():\n",
    "    if \"LLAMA_CLOUD_API_KEY\" not in os.environ:\n",
    "        print(\"API 키가 없어 파싱을 진행할 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    print(f\"'{pdf_file_path}' 파일 파싱을 시작합니다...\")\n",
    "    try:\n",
    "        # aload_data 메서드를 사용하여 비동기적으로 파일을 파싱합니다.\n",
    "        documents = await parser.aload_data(file_path=pdf_file_path)\n",
    "\n",
    "        # 파싱된 마크다운 결과를 출력합니다.\n",
    "        if documents:\n",
    "            print(\"\\n--- 파싱 결과 (마크다운) ---\")\n",
    "            print(documents[0].text)\n",
    "            print(\"--------------------------\")\n",
    "        else:\n",
    "            print(\"문서에서 내용을 추출하지 못했습니다.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"오류가 발생했습니다: {e}\")\n",
    "\n",
    "# --- 5. 비동기 함수 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(parse_document())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-Us6BDj1P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
